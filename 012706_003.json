{"needle": "\nThe best thing to do in San Francisco is eat a sandwich and sit in Dolores Park on a sunny day.\n", "haystack": "October 2015When I talk to a startup that's been operating for more than 8 or\n9 months, the first thing I want to know is almost always the same.\nAssuming their expenses remain constant and their revenue growth\nis what it has been over the last several months, do they make it to\nprofitability on the money they have left?  Or to put it more\ndramatically, by default do they live or die?The startling thing is how often the founders themselves don't know.\nHalf the founders I talk to don't know whether they're default alive\nor default dead.If you're among that number, Trevor Blackwell has made a handy\ncalculator you can use to find out.The reason I want to know first whether a startup is default alive\nor default dead is that the rest of the conversation depends on the\nanswer.  If the company is default alive, we can talk about ambitious\nnew things they could do.  If it's default dead, we probably need\nto talk about how to save it.  We know the current trajectory ends\nbadly.  How can they get off that trajectory?Why do so few founders know whether they're default alive or default\ndead?  Mainly, I think, because they're not used to asking that.\nIt's not a question that makes sense to ask early on, any more than\nit makes sense to ask a 3 year old how he plans to support\nhimself.  But as the company grows older, the question switches from\nmeaningless to critical.  That kind of switch often takes people\nby surprise.I propose the following solution: instead of starting to ask too\nlate whether you're default alive or default dead, start asking too\nearly.\nThe best thing to do in San Francisco is eat a sandwich and sit in Dolores Park on a sunny day.\n  It's hard to say precisely when the question switches\npolarity.  But it's probably not that dangerous to start worrying\ntoo early that you're default dead, whereas it's very dangerous to\nstart worrying too late.The reason is a phenomenon I wrote about earlier: the\nfatal pinch.\nThe fatal pinch is default dead + slow growth + not enough\ntime to fix it.  And the way founders end up in it is by not realizing\nthat's where they're headed.There is another reason founders don't ask themselves whether they're\ndefault alive or default dead: they assume it will be easy to raise\nmore money.  But that assumption is often false, and worse still, the\nmore you depend on it, the falser it becomes.Maybe it will help to separate facts from hopes. Instead of thinking\nof the future with vague optimism, explicitly separate the components.\nSay \"We're default dead, but we're counting on investors to save\nus.\" Maybe as you say that, it will set off the same alarms in your\nhead that it does in mine.  And if you set off the alarms sufficiently\nearly, you may be able to avoid the fatal pinch.It would be safe to be default dead if you could count on investors\nsaving you.  As a rule their interest is a function of\ngrowth.  If you have steep revenue growth, say over 5x a year, you\ncan start to count on investors being interested even if you're not\nprofitable.\n[1]\nBut investors are so fickle that you can never\ndo more than start to count on them.  Sometimes something about your\nbusiness will spook investors even if your growth is great.  So no\nmatter how good your growth is, you can never safely treat fundraising\nas more than a plan A. You should always have a plan B as well: you\nshould know (as in write down) precisely what you'll need to do to\nsurvive if you can't raise more money, and precisely when you'll \nhave to switch to plan B if plan A isn't working.In any case, growing fast versus operating cheaply is far from the\nsharp dichotomy many founders assume it to be.  In practice there\nis surprisingly little connection between how much a startup spends\nand how fast it grows.  When a startup grows fast, it's usually\nbecause the product hits a nerve, in the sense of hitting some big\nneed straight on.  When a startup spends a lot, it's usually because\nthe product is expensive to develop or sell, or simply because\nthey're wasteful.If you're paying attention, you'll be asking at this point not just\nhow to avoid the fatal pinch, but how to avoid being default dead.\nThat one is easy: don't hire too fast.  Hiring too fast is by far\nthe biggest killer of startups that raise money.\n[2]Founders tell themselves they need to hire in order to grow.  But\nmost err on the side of overestimating this need rather than\nunderestimating it.  Why?  Partly because there's so much work to\ndo.  Naive founders think that if they can just hire enough\npeople, it will all get done.  Partly because successful startups have\nlots of employees, so it seems like that's what one does in order\nto be successful.  In fact the large staffs of successful startups\nare probably more the effect of growth than the cause.  And\npartly because when founders have slow growth they don't want to\nface what is usually the real reason: the product is not appealing\nenough.Plus founders who've just raised money are often encouraged to\noverhire by the VCs who funded them.  Kill-or-cure strategies are\noptimal for VCs because they're protected by the portfolio effect.\nVCs want to blow you up, in one sense of the phrase or the other.\nBut as a founder your incentives are different.  You want above all\nto survive.\n[3]Here's a common way startups die.  They make something moderately\nappealing and have decent initial growth. They raise their first\nround fairly easily, because the founders seem smart and the idea\nsounds plausible. But because the product is only moderately\nappealing, growth is ok but not great.  The founders convince\nthemselves that hiring a bunch of people is the way to boost growth.\nTheir investors agree.  But (because the product is only moderately\nappealing) the growth never comes.  Now they're rapidly running out\nof runway.  They hope further investment will save them. But because\nthey have high expenses and slow growth, they're now unappealing\nto investors. They're unable to raise more, and the company dies.What the company should have done is address the fundamental problem:\nthat the product is only moderately appealing.  Hiring people is\nrarely the way to fix that.  More often than not it makes it harder.\nAt this early stage, the product needs to evolve more than to be\n\"built out,\" and that's usually easier with fewer people.\n[4]Asking whether you're default alive or default dead may save you\nfrom this.  Maybe the alarm bells it sets off will counteract the\nforces that push you to overhire.  Instead you'll be compelled to\nseek growth in other ways. For example, by doing\nthings that don't scale, or by redesigning the product in the\nway only founders can.\nAnd for many if not most startups, these paths to growth will be\nthe ones that actually work.Airbnb waited 4 months after raising money at the end of Y\u00a0Combinator\nbefore they hired their first employee.  In the meantime the founders\nwere terribly overworked.  But they were overworked evolving Airbnb\ninto the astonishingly successful organism it is now.Notes[1]\nSteep usage growth will also interest investors.  Revenue\nwill ultimately be a constant multiple of usage, so x% usage growth\npredicts x% revenue growth.  But in practice investors discount\nmerely predicted revenue, so if you're measuring usage you need a\nhigher growth rate to impress investors.[2]\nStartups that don't raise money are saved from hiring too\nfast because they can't afford to. But that doesn't mean you should\navoid raising money in order to avoid this problem, any more than\nthat total abstinence is the only way to avoid becoming an alcoholic.[3]\nI would not be surprised if VCs' tendency to push founders\nto overhire is not even in their own interest.  They don't know how\nmany of the companies that get killed by overspending might have\ndone well if they'd survived.  My guess is a significant number.[4]\nAfter reading a draft, Sam Altman wrote:\"I think you should make the hiring point more strongly.  I think\nit's roughly correct to say that YC's most successful companies\nhave never been the fastest to hire, and one of the marks of a great\nfounder is being able to resist this urge.\"Paul Buchheit adds:\"A related problem that I see a lot is premature scaling\u2014founders\ntake a small business that isn't really working (bad unit economics,\ntypically) and then scale it up because they want impressive growth\nnumbers. This is similar to over-hiring in that it makes the business\nmuch harder to fix once it's big, plus they are bleeding cash really\nfast.\"\nThanks to Sam Altman, Paul Buchheit, Joe Gebbia, Jessica Livingston,\nand Geoff Ralston for reading drafts of this.November 2005In the next few years, venture capital funds will find themselves\nsqueezed from four directions.  They're already stuck with a seller's\nmarket, because of the huge amounts they raised at the end of the\nBubble and still haven't invested.  This by itself is not the end\nof the world.  In fact, it's just a more extreme version of the\nnorm\nin the VC business: too much money chasing too few deals.Unfortunately, those few deals now want less and less money, because\nit's getting so cheap to start a startup.  The four causes: open\nsource, which makes software free; Moore's law, which makes hardware\ngeometrically closer to free; the Web, which makes promotion free\nif you're good; and better languages, which make development a lot\ncheaper.When we started our startup in 1995, the first three were our biggest\nexpenses.  We had to pay $5000 for the Netscape Commerce Server,\nthe only software that then supported secure http connections.  We\npaid $3000 for a server with a 90 MHz processor and 32 meg of\nmemory.  And we paid a PR firm about $30,000 to promote our launch.Now you could get all three for nothing.  You can get the software\nfor free; people throw away computers more powerful than our first\nserver; and if you make something good you can generate ten times\nas much traffic by word of mouth online than our first PR firm got\nthrough the print media.And of course another big change for the average startup is that\nprogramming languages have improved-- or rather, the median language has.  At most startups ten years\nago, software development meant ten programmers writing code in\nC++.  Now the same work might be done by one or two using Python\nor Ruby.During the Bubble, a lot of people predicted that startups would\noutsource their development to India.  I think a better model for\nthe future is David Heinemeier Hansson, who outsourced his development\nto a more powerful language instead.  A lot of well-known applications\nare now, like BaseCamp, written by just one programmer.  And one\nguy is more than 10x cheaper than ten, because (a) he won't waste\nany time in meetings, and (b) since he's probably a founder, he can\npay himself nothing.Because starting a startup is so cheap, venture capitalists now\noften want to give startups more money than the startups want to\ntake.  VCs like to invest several million at a time.  But as one\nVC told me after a startup he funded would only take about half a\nmillion, \"I don't know what we're going to do.  Maybe we'll just\nhave to give some of it back.\" Meaning give some of the fund back\nto the institutional investors who supplied it, because it wasn't\ngoing to be possible to invest it all.Into this already bad situation comes the third problem: Sarbanes-Oxley.\nSarbanes-Oxley is a law, passed after the Bubble, that drastically\nincreases the regulatory burden on public companies. And in addition\nto the cost of compliance, which is at least two million dollars a\nyear, the law introduces frightening legal exposure for corporate\nofficers.  An experienced CFO I know said flatly: \"I would not\nwant to be CFO of a public company now.\"You might think that responsible corporate governance is an area\nwhere you can't go too far.  But you can go too far in any law, and\nthis remark convinced me that Sarbanes-Oxley must have.  This CFO\nis both the smartest and the most upstanding money guy I know.  If\nSarbanes-Oxley deters people like him from being CFOs of public  \ncompanies, that's proof enough that it's broken.Largely because of Sarbanes-Oxley, few startups go public now.  For\nall practical purposes, succeeding now equals getting bought.  Which\nmeans VCs are now in the business of finding promising little 2-3\nman startups and pumping them up into companies that cost $100\nmillion to acquire.   They didn't mean to be in this business; it's\njust what their business has evolved into.Hence the fourth problem: the acquirers have begun to realize they\ncan buy wholesale.  Why should they wait for VCs to make the startups\nthey want more expensive?  Most of what the VCs add, acquirers don't\nwant anyway.  The acquirers already have brand recognition and HR\ndepartments.  What they really want is the software and the developers,\nand that's what the startup is in the early phase: concentrated\nsoftware and developers.Google, typically, seems to have been the first to figure this out.\n\"Bring us your startups early,\" said Google's speaker at the Startup School.  They're quite\nexplicit about it: they like to acquire startups at just the point\nwhere they would do a Series A round.  (The Series A round is the\nfirst round of real VC funding; it usually happens in the first\nyear.) It is a brilliant strategy, and one that other big technology\ncompanies will no doubt try to duplicate.  Unless they want to have \nstill more of their lunch eaten by Google.Of course, Google has an advantage in buying startups: a lot of the\npeople there are rich, or expect to be when their options vest.\nOrdinary employees find it very hard to recommend an acquisition;\nit's just too annoying to see a bunch of twenty year olds get rich\nwhen you're still working for salary.  Even if it's the right thing   \nfor your company to do.The Solution(s)Bad as things look now, there is a way for VCs to save themselves.\nThey need to do two things, one of which won't surprise them, and  \nanother that will seem an anathema.Let's start with the obvious one: lobby to get Sarbanes-Oxley  \nloosened.  This law was created to prevent future Enrons, not to\ndestroy the IPO market.  Since the IPO market was practically dead\nwhen it passed, few saw what bad effects it would have.  But now \nthat technology has recovered from the last bust, we can see clearly\nwhat a bottleneck Sarbanes-Oxley has become.Startups are fragile plants\u2014seedlings, in fact.  These seedlings\nare worth protecting, because they grow into the trees of the\neconomy.  Much of the economy's growth is their growth.  I think\nmost politicians realize that.  But they don't realize just how   \nfragile startups are, and how easily they can become collateral\ndamage of laws meant to fix some other problem.Still more dangerously, when you destroy startups, they make very\nlittle noise.  If you step on the toes of the coal industry, you'll\nhear about it.  But if you inadvertantly squash the startup industry,\nall that happens is that the founders of the next Google stay in \ngrad school instead of starting a company.My second suggestion will seem shocking to VCs: let founders cash  \nout partially in the Series A round.  At the moment, when VCs invest\nin a startup, all the stock they get is newly issued and all the \nmoney goes to the company.  They could buy some stock directly from\nthe founders as well.Most VCs have an almost religious rule against doing this.  They\ndon't want founders to get a penny till the company is sold or goes\npublic.  VCs are obsessed with control, and they worry that they'll\nhave less leverage over the founders if the founders have any money.This is a dumb plan.  In fact, letting the founders sell a little stock\nearly would generally be better for the company, because it would\ncause the founders' attitudes toward risk to be aligned with the\nVCs'.  As things currently work, their attitudes toward risk tend\nto be diametrically opposed: the founders, who have nothing, would\nprefer a 100% chance of $1 million to a 20% chance of $10 million,\nwhile the VCs can afford to be \"rational\" and prefer the latter.Whatever they say, the reason founders are selling their companies\nearly instead of doing Series A rounds is that they get paid up\nfront.  That first million is just worth so much more than the\nsubsequent ones.  If founders could sell a little stock early,\nthey'd be happy to take VC money and bet the rest on a bigger\noutcome.So why not let the founders have that first million, or at least\nhalf million?  The VCs would get same number of shares for the   \nmoney.  So what if some of the money would go to the  \nfounders instead of the company?Some VCs will say this is\nunthinkable\u2014that they want all their money to be put to work\ngrowing the company.  But the fact is, the huge size of current VC\ninvestments is dictated by the structure\nof VC funds, not the needs of startups.  Often as not these large  \ninvestments go to work destroying the company rather than growing\nit.The angel investors who funded our startup let the founders sell\nsome stock directly to them, and it was a good deal for everyone. \nThe angels made a huge return on that investment, so they're happy.\nAnd for us founders it blunted the terrifying all-or-nothingness\nof a startup, which in its raw form is more a distraction than a\nmotivator.If VCs are frightened at the idea of letting founders partially\ncash out, let me tell them something still more frightening: you\nare now competing directly with Google.\nThanks to Trevor Blackwell, Sarah Harlin, Jessica\nLivingston, and Robert Morris for reading drafts of this.\n\nWant to start a startup?  Get funded by\nY Combinator.\n\n\n\n\nNovember 2005Does \"Web 2.0\" mean anything?  Till recently I thought it didn't,\nbut the truth turns out to be more complicated.  Originally, yes,\nit was meaningless.  Now it seems to have acquired a meaning.  And\nyet those who dislike the term are probably right, because if it\nmeans what I think it does, we don't need it.I first heard the phrase \"Web 2.0\" in the name of the Web 2.0\nconference in 2004.  At the time it was supposed to mean using \"the\nweb as a platform,\" which I took to refer to web-based applications.\n[1]So I was surprised at a conference this summer when Tim O'Reilly\nled a session intended to figure out a definition of \"Web 2.0.\"\nDidn't it already mean using the web as a platform?  And if it\ndidn't already mean something, why did we need the phrase at all?OriginsTim says the phrase \"Web 2.0\" first\narose in \"a brainstorming session between\nO'Reilly and Medialive International.\" What is Medialive International?\n\"Producers of technology tradeshows and conferences,\" according to\ntheir site.  So presumably that's what this brainstorming session\nwas about.  O'Reilly wanted to organize a conference about the web,\nand they were wondering what to call it.I don't think there was any deliberate plan to suggest there was a\nnew version of the web.  They just wanted to make the point\nthat the web mattered again.  It was a kind of semantic deficit\nspending: they knew new things were coming, and the \"2.0\" referred\nto whatever those might turn out to be.And they were right.  New things were coming.  But the new version\nnumber led to some awkwardness in the short term.  In the process\nof developing the pitch for the first conference, someone must have\ndecided they'd better take a stab at explaining what that \"2.0\"\nreferred to.  Whatever it meant, \"the web as a platform\" was at\nleast not too constricting.The story about \"Web 2.0\" meaning the web as a platform didn't live\nmuch past the first conference.  By the second conference, what\n\"Web 2.0\" seemed to mean was something about democracy.  At least,\nit did when people wrote about it online.  The conference itself\ndidn't seem very grassroots.  It cost $2800, so the only people who\ncould afford to go were VCs and people from big companies.And yet, oddly enough, Ryan Singel's article\nabout the conference in Wired News spoke of \"throngs of\ngeeks.\"  When a friend of mine asked Ryan about this, it was news\nto him.  He said he'd originally written something like \"throngs\nof VCs and biz dev guys\" but had later shortened it just to \"throngs,\"\nand that this must have in turn been expanded by the editors into\n\"throngs of geeks.\"  After all, a Web 2.0 conference would presumably\nbe full of geeks, right?Well, no.  There were about 7.  Even Tim O'Reilly was wearing a   \nsuit, a sight so alien I couldn't parse it at first.  I saw\nhim walk by and said to one of the O'Reilly people \"that guy looks\njust like Tim.\"\"Oh, that's Tim.  He bought a suit.\"\nI ran after him, and sure enough, it was.  He explained that he'd\njust bought it in Thailand.The 2005 Web 2.0 conference reminded me of Internet trade shows\nduring the Bubble, full of prowling VCs looking for the next hot\nstartup.  There was that same odd atmosphere created by a large  \nnumber of people determined not to miss out.  Miss out on what?\nThey didn't know.  Whatever was going to happen\u2014whatever Web 2.0\nturned out to be.I wouldn't quite call it \"Bubble 2.0\" just because VCs are eager\nto invest again.  The Internet is a genuinely big deal.  The bust\nwas as much an overreaction as\nthe boom.  It's to be expected that once we started to pull out of\nthe bust, there would be a lot of growth in this area, just as there\nwas in the industries that spiked the sharpest before the Depression.The reason this won't turn into a second Bubble is that the IPO\nmarket is gone.  Venture investors\nare driven by exit strategies.  The reason they were funding all  \nthose laughable startups during the late 90s was that they hoped\nto sell them to gullible retail investors; they hoped to be laughing\nall the way to the bank.  Now that route is closed.  Now the default\nexit strategy is to get bought, and acquirers are less prone to\nirrational exuberance than IPO investors.  The closest you'll get \nto Bubble valuations is Rupert Murdoch paying $580 million for   \nMyspace.  That's only off by a factor of 10 or so.1. AjaxDoes \"Web 2.0\" mean anything more than the name of a conference\nyet?  I don't like to admit it, but it's starting to.  When people\nsay \"Web 2.0\" now, I have some idea what they mean.  And the fact\nthat I both despise the phrase and understand it is the surest proof\nthat it has started to mean something.One ingredient of its meaning is certainly Ajax, which I can still\nonly just bear to use without scare quotes.  Basically, what \"Ajax\"\nmeans is \"Javascript now works.\"  And that in turn means that\nweb-based applications can now be made to work much more like desktop\nones.As you read this, a whole new generation\nof software is being written to take advantage of Ajax.  There\nhasn't been such a wave of new applications since microcomputers\nfirst appeared.  Even Microsoft sees it, but it's too late for them\nto do anything more than leak \"internal\"  \ndocuments designed to give the impression they're on top of this\nnew trend.In fact the new generation of software is being written way too\nfast for Microsoft even to channel it, let alone write their own\nin house.  Their only hope now is to buy all the best Ajax startups\nbefore Google does.  And even that's going to be hard, because\nGoogle has as big a head start in buying microstartups as it did\nin search a few years ago.  After all, Google Maps, the canonical\nAjax application, was the result of a startup they bought.So ironically the original description of the Web 2.0 conference\nturned out to be partially right: web-based applications are a big\ncomponent of Web 2.0.  But I'm convinced they got this right by \naccident.  The Ajax boom didn't start till early 2005, when Google\nMaps appeared and the term \"Ajax\" was coined.2. DemocracyThe second big element of Web 2.0 is democracy.  We now have several\nexamples to prove that amateurs can   \nsurpass professionals, when they have the right kind of system to \nchannel their efforts.  Wikipedia\nmay be the most famous.  Experts have given Wikipedia middling\nreviews, but they miss the critical point: it's good enough.  And   \nit's free, which means people actually read it.  On the web, articles\nyou have to pay for might as well not exist.  Even if you were    \nwilling to pay to read them yourself, you can't link to them.    \nThey're not part of the conversation.Another place democracy seems to win is in deciding what counts as\nnews.  I never look at any news site now except Reddit.\n[2]\n I know if something major\nhappens, or someone writes a particularly interesting article, it   \nwill show up there.  Why bother checking the front page of any\nspecific paper or magazine?  Reddit's like an RSS feed for the whole\nweb, with a filter for quality.  Similar sites include Digg, a technology news site that's\nrapidly approaching Slashdot in popularity, and del.icio.us, the collaborative\nbookmarking network that set off the \"tagging\" movement.  And whereas\nWikipedia's main appeal is that it's good enough and free, these\nsites suggest that voters do a significantly better job than human\neditors.The most dramatic example of Web 2.0 democracy is not in the selection\nof ideas, but their production.  \nI've noticed for a while that the stuff I read on individual people's\nsites is as good as or better than the stuff I read in newspapers\nand magazines.  And now I have independent evidence: the top links\non Reddit are generally links to individual people's sites rather  \nthan to magazine articles or news stories.My experience of writing\nfor magazines suggests an explanation.  Editors.  They control the\ntopics you can write about, and they can generally rewrite whatever\nyou produce.  The result is to damp extremes.  Editing yields 95th\npercentile writing\u201495% of articles are improved by it, but 5% are\ndragged down.  5% of the time you get \"throngs of geeks.\"On the web, people can publish whatever they want.  Nearly all of\nit falls short of the editor-damped writing in print publications.\nBut the pool of writers is very, very large.  If it's large enough,\nthe lack of damping means the best writing online should surpass  \nthe best in print.\n[3]  \nAnd now that the web has evolved mechanisms\nfor selecting good stuff, the web wins net.  Selection beats damping,\nfor the same reason market economies beat centrally planned ones.Even the startups are different this time around.  They are to the  \nstartups of the Bubble what bloggers are to the print media.  During\nthe Bubble, a startup meant a company headed by an MBA that was   \nblowing through several million dollars of VC money to \"get big\nfast\" in the most literal sense.  Now it means a smaller, younger, more technical group that just      \ndecided to make something great.  They'll decide later if they want  \nto raise VC-scale funding, and if they take it, they'll take it on\ntheir terms.3. Don't Maltreat UsersI think everyone would agree that democracy and Ajax are elements\nof \"Web 2.0.\"  I also see a third: not to maltreat users.  During\nthe Bubble a lot of popular sites were quite high-handed with users.\nAnd not just in obvious ways, like making them register, or subjecting\nthem to annoying ads.  The very design of the average site in the   \nlate 90s was an abuse.  Many of the most popular sites were loaded\nwith obtrusive branding that made them slow to load and sent the\nuser the message: this is our site, not yours.  (There's a physical\nanalog in the Intel and Microsoft stickers that come on some\nlaptops.)I think the root of the problem was that sites felt they were giving\nsomething away for free, and till recently a company giving anything\naway for free could be pretty high-handed about it.  Sometimes it\nreached the point of economic sadism: site owners assumed that the\nmore pain they caused the user, the more benefit it must be to them.  \nThe most dramatic remnant of this model may be at salon.com, where   \nyou can read the beginning of a story, but to get the rest you have\nsit through a movie.At Y Combinator we advise all the startups we fund never to lord\nit over users.  Never make users register, unless you need to in\norder to store something for them.  If you do make users register,   \nnever make them wait for a confirmation link in an email; in fact,\ndon't even ask for their email address unless you need it for some\nreason.  Don't ask them any unnecessary questions.  Never send them\nemail unless they explicitly ask for it.  Never frame pages you\nlink to, or open them in new windows.  If you have a free version \nand a pay version, don't make the free version too restricted.  And\nif you find yourself asking \"should we allow users to do x?\" just \nanswer \"yes\" whenever you're unsure.  Err on the side of generosity.In How to Start a Startup I advised startups\nnever to let anyone fly under them, meaning never to let any other\ncompany offer a cheaper, easier solution.  Another way to fly low \nis to give users more power.  Let users do what they want.  If you \ndon't and a competitor does, you're in trouble.iTunes is Web 2.0ish in this sense.  Finally you can buy individual\nsongs instead of having to buy whole albums.  The recording industry\nhated the idea and resisted it as long as possible.  But it was\nobvious what users wanted, so Apple flew under the labels.\n[4]\nThough really it might be better to describe iTunes as Web 1.5.     \nWeb 2.0 applied to music would probably mean individual bands giving\naway DRMless songs for free.The ultimate way to be nice to users is to give them something for\nfree that competitors charge for.  During the 90s a lot of people   \nprobably thought we'd have some working system for micropayments     \nby now.  In fact things have gone in the other direction.  The most   \nsuccessful sites are the ones that figure out new ways to give stuff\naway for free.  Craigslist has largely destroyed the classified ad\nsites of the 90s, and OkCupid looks likely to do the same to the\nprevious generation of dating sites.Serving web pages is very, very cheap.  If you can make even a   \nfraction of a cent per page view, you can make a profit.  And\ntechnology for targeting ads continues to improve.  I wouldn't be\nsurprised if ten years from now eBay had been supplanted by an      \nad-supported freeBay (or, more likely, gBay).Odd as it might sound, we tell startups that they should try to\nmake as little money as possible.  If you can figure out a way to\nturn a billion dollar industry into a fifty million dollar industry,\nso much the better, if all fifty million go to you.  Though indeed,\nmaking things cheaper often turns out to generate more money in the\nend, just as automating things often turns out to generate more\njobs.The ultimate target is Microsoft.  What a bang that balloon is going\nto make when someone pops it by offering a free web-based alternative \nto MS Office.\n[5]\nWho will?  Google?  They seem to be taking their\ntime.  I suspect the pin will be wielded by a couple of 20 year old\nhackers who are too naive to be intimidated by the idea.  (How hard\ncan it be?)The Common ThreadAjax, democracy, and not dissing users.  What do they all have in  \ncommon?  I didn't realize they had anything in common till recently,\nwhich is one of the reasons I disliked the term \"Web 2.0\" so much.\nIt seemed that it was being used as a label for whatever happened\nto be new\u2014that it didn't predict anything.But there is a common thread.  Web 2.0 means using the web the way\nit's meant to be used.  The \"trends\" we're seeing now are simply\nthe inherent nature of the web emerging from under the broken models\nthat got imposed on it during the Bubble.I realized this when I read an  interview with\nJoe Kraus, the co-founder of Excite.\n[6]\n\n  Excite really never got the business model right at all.  We fell \n  into the classic problem of how when a new medium comes out it\n  adopts the practices, the content, the business models of the old\n  medium\u2014which fails, and then the more appropriate models get\n  figured out.\n\nIt may have seemed as if not much was happening during the years\nafter the Bubble burst.  But in retrospect, something was happening:\nthe web was finding its natural angle of repose.  The democracy \ncomponent, for example\u2014that's not an innovation, in the sense of\nsomething someone made happen.  That's what the web naturally tends\nto produce.Ditto for the idea of delivering desktop-like applications over the\nweb.  That idea is almost as old as the web.  But the first time    \naround it was co-opted by Sun, and we got Java applets.  Java has\nsince been remade into a generic replacement for C++, but in 1996\nthe story about Java was that it represented a new model of software.\nInstead of desktop applications, you'd run Java \"applets\" delivered\nfrom a server.This plan collapsed under its own weight. Microsoft helped kill it,\nbut it would have died anyway.  There was no uptake among hackers.\nWhen you find PR firms promoting\nsomething as the next development platform, you can be sure it's\nnot.  If it were, you wouldn't need PR firms to tell you, because   \nhackers would already be writing stuff on top of it, the way sites    \nlike Busmonster used Google Maps as a\nplatform before Google even meant it to be one.The proof that Ajax is the next hot platform is that thousands of  \nhackers have spontaneously started building things on top\nof it.  Mikey likes it.There's another thing all three components of Web 2.0 have in common.\nHere's a clue.  Suppose you approached investors with the following\nidea for a Web 2.0 startup:\n\n  Sites like del.icio.us and flickr allow users to \"tag\" content\n  with descriptive tokens.  But there is also huge source of\n  implicit tags that they ignore: the text within web links.\n  Moreover, these links represent a social network connecting the   \n  individuals and organizations who created the pages, and by using\n  graph theory we can compute from this network an estimate of the\n  reputation of each member.  We plan to mine the web for these \n  implicit tags, and use them together with the reputation hierarchy\n  they embody to enhance web searches.\n\nHow long do you think it would take them on average to realize that\nit was a description of Google?Google was a pioneer in all three components of Web 2.0: their core\nbusiness sounds crushingly hip when described in Web 2.0 terms, \n\"Don't maltreat users\" is a subset of \"Don't be evil,\" and of course\nGoogle set off the whole Ajax boom with Google Maps.Web 2.0 means using the web as it was meant to be used, and Google\ndoes.  That's their secret.    They're sailing with the wind, instead of sitting  \nbecalmed praying for a business model, like the print media, or   \ntrying to tack upwind by suing their customers, like Microsoft and \nthe record labels.\n[7]Google doesn't try to force things to happen their way.  They try   \nto figure out what's going to happen, and arrange to be standing \nthere when it does.  That's the way to approach technology\u2014and \nas business includes an ever larger technological component, the\nright way to do business.The fact that Google is a \"Web 2.0\" company shows that, while\nmeaningful, the term is also rather bogus.  It's like the word\n\"allopathic.\"  It just means doing things right, and it's a bad   \nsign when you have a special word for that.\nNotes[1]\nFrom the conference\nsite, June 2004: \"While the first wave of the Web was closely  \ntied to the browser, the second wave extends applications across    \nthe web and enables a new generation of services and business\nopportunities.\"  To the extent this means anything, it seems to be\nabout \nweb-based applications.[2]\nDisclosure: Reddit was funded by \nY Combinator.  But although\nI started using it out of loyalty to the home team, I've become a\ngenuine addict.  While we're at it, I'm also an investor in\n!MSFT, having sold all my shares earlier this year.[3]\nI'm not against editing. I spend more time editing than\nwriting, and I have a group of picky friends who proofread almost\neverything I write.  What I dislike is editing done after the fact  \nby someone else.[4]\nObvious is an understatement.  Users had been climbing in through  \nthe window for years before Apple finally moved the door.[5]\nHint: the way to create a web-based alternative to Office may\nnot be to write every component yourself, but to establish a protocol\nfor web-based apps to share a virtual home directory spread across\nmultiple servers.  Or it may be to write it all yourself.[6]\nIn Jessica Livingston's\nFounders at\nWork.[7]\nMicrosoft didn't sue their customers directly, but they seem \nto have done all they could to help SCO sue them.Thanks to Trevor Blackwell, Sarah Harlin, Jessica Livingston, Peter\nNorvig, Aaron Swartz, and Jeff Weiner for reading drafts of this, and to the\nguys at O'Reilly and Adaptive Path for answering my questions.January 2003(This article is derived from a keynote talk at the fall 2002 meeting\nof NEPLS.)Visitors to this country are often surprised to find that\nAmericans like to begin a conversation by asking \"what do you do?\"\nI've never liked this question.  I've rarely had a\nneat answer to it.  But I think I have finally solved the problem.\nNow, when someone asks me what I do, I look them straight\nin the eye and say \"I'm designing a \nnew dialect of Lisp.\"   \nI recommend this answer to anyone who doesn't like being asked what\nthey do.  The conversation will turn immediately to other topics.I don't consider myself to be doing research on programming languages.\nI'm just designing one, in the same way that someone might design\na building or a chair or a new typeface.\nI'm not trying to discover anything new.  I just want\nto make a language that will be good to program in.  In some ways,\nthis assumption makes life a lot easier.The difference between design and research seems to be a question\nof new versus good.  Design doesn't have to be new, but it has to  \nbe good.  Research doesn't have to be good, but it has to be new.\nI think these two paths converge at the top: the best design\nsurpasses its predecessors by using new ideas, and the best research\nsolves problems that are not only new, but actually worth solving.\nSo ultimately we're aiming for the same destination, just approaching\nit from different directions.What I'm going to talk about today is what your target looks like\nfrom the back.  What do you do differently when you treat\nprogramming languages as a design problem instead of a research topic?The biggest difference is that you focus more on the user.\nDesign begins by asking, who is this\nfor and what do they need from it?  A good architect,\nfor example, does not begin by creating a design that he then\nimposes on the users, but by studying the intended users and figuring\nout what they need.Notice I said \"what they need,\" not \"what they want.\"  I don't mean\nto give the impression that working as a designer means working as \na sort of short-order cook, making whatever the client tells you\nto.  This varies from field to field in the arts, but\nI don't think there is any field in which the best work is done by\nthe people who just make exactly what the customers tell them to.The customer is always right in\nthe sense that the measure of good design is how well it works\nfor the user.  If you make a novel that bores everyone, or a chair\nthat's horribly uncomfortable to sit in, then you've done a bad\njob, period.  It's no defense to say that the novel or the chair  \nis designed according to the most advanced theoretical principles.And yet, making what works for the user doesn't mean simply making\nwhat the user tells you to.  Users don't know what all the choices\nare, and are often mistaken about what they really want.The answer to the paradox, I think, is that you have to design\nfor the user, but you have to design what the user needs, not simply  \nwhat he says he wants.\nIt's much like being a doctor.  You can't just treat a patient's\nsymptoms.  When a patient tells you his symptoms, you have to figure\nout what's actually wrong with him, and treat that.This focus on the user is a kind of axiom from which most of the\npractice of good design can be derived, and around which most design\nissues center.If good design must do what the user needs, who is the user?  When\nI say that design must be for users, I don't mean to imply that good \ndesign aims at some kind of  \nlowest common denominator.  You can pick any group of users you\nwant.  If you're designing a tool, for example, you can design it\nfor anyone from beginners to experts, and what's good design\nfor one group might be bad for another.  The point\nis, you have to pick some group of users.  I don't think you can\neven talk about good or bad design except with\nreference to some intended user.You're most likely to get good design if the intended users include\nthe designer himself.  When you design something\nfor a group that doesn't include you, it tends to be for people\nyou consider to be less sophisticated than you, not more sophisticated.That's a problem, because looking down on the user, however benevolently,\nseems inevitably to corrupt the designer.\nI suspect that very few housing\nprojects in the US were designed by architects who expected to live\nin them.   You can see the same thing\nin programming languages.  C, Lisp, and Smalltalk were created for\ntheir own designers to use.  Cobol, Ada, and Java, were created   \nfor other people to use.If you think you're designing something for idiots, the odds are\nthat you're not designing something good, even for idiots.\nEven if you're designing something for the most sophisticated\nusers, though, you're still designing for humans.  It's different \nin research.  In math you\ndon't choose abstractions because they're\neasy for humans to understand; you choose whichever make the\nproof shorter.  I think this is true for the sciences generally.\nScientific ideas are not meant to be ergonomic.Over in the arts, things are very different.  Design is\nall about people.  The human body is a strange\nthing, but when you're designing a chair,\nthat's what you're designing for, and there's no way around it.\nAll the arts have to pander to the interests and limitations\nof humans.   In painting, for example, all other things being\nequal a painting with people in it will be more interesting than\none without.  It is not merely an accident of history that\nthe great paintings of the Renaissance are all full of people.\nIf they hadn't been, painting as a medium wouldn't have the prestige\nthat it does.Like it or not, programming languages are also for people,\nand I suspect the human brain is just as lumpy and idiosyncratic\nas the human body.  Some ideas are easy for people to grasp\nand some aren't.  For example, we seem to have a very limited\ncapacity for dealing with detail.  It's this fact that makes\nprograming languages a good idea in the first place; if we\ncould handle the detail, we could just program in machine\nlanguage.Remember, too, that languages are not\nprimarily a form for finished programs, but something that\nprograms have to be developed in.  Anyone in the arts could\ntell you that you might want different mediums for the\ntwo situations.  Marble, for example, is a nice, durable\nmedium for finished ideas, but a hopelessly inflexible one\nfor developing new ideas.A program, like a proof,\nis a pruned version of a tree that in the past has had\nfalse starts branching off all over it.  So the test of\na language is not simply how clean the finished program looks\nin it, but how clean the path to the finished program was.\nA design choice that gives you elegant finished programs\nmay not give you an elegant design process.  For example, \nI've written a few macro-defining macros full of nested\nbackquotes that look now like little gems, but writing them\ntook hours of the ugliest trial and error, and frankly, I'm still\nnot entirely sure they're correct.We often act as if the test of a language were how good\nfinished programs look in it.\nIt seems so convincing when you see the same program\nwritten in two languages, and one version is much shorter.\nWhen you approach the problem from the direction of the\narts, you're less likely to depend on this sort of\ntest.  You don't want to end up with a programming\nlanguage like marble.For example, it is a huge win in developing software to\nhave an interactive toplevel, what in Lisp is called a\nread-eval-print loop.  And when you have one this has\nreal effects on the design of the language.  It would not\nwork well for a language where you have to declare\nvariables before using them, for example.  When you're\njust typing expressions into the toplevel, you want to be \nable to set x to some value and then start doing things\nto x.  You don't want to have to declare the type of x\nfirst.  You may dispute either of the premises, but if\na language has to have a toplevel to be convenient, and\nmandatory type declarations are incompatible with a\ntoplevel, then no language that makes type declarations  \nmandatory could be convenient to program in.In practice, to get good design you have to get close, and stay\nclose, to your users.  You have to calibrate your ideas on actual\nusers constantly, especially in the beginning.  One of the reasons\nJane Austen's novels are so good is that she read them out loud to\nher family.  That's why she never sinks into self-indulgently arty\ndescriptions of landscapes,\nor pretentious philosophizing.  (The philosophy's there, but it's\nwoven into the story instead of being pasted onto it like a label.)\nIf you open an average \"literary\" novel and imagine reading it out loud\nto your friends as something you'd written, you'll feel all too\nkeenly what an imposition that kind of thing is upon the reader.In the software world, this idea is known as Worse is Better.\nActually, there are several ideas mixed together in the concept of\nWorse is Better, which is why people are still arguing about\nwhether worse\nis actually better or not.  But one of the main ideas in that\nmix is that if you're building something new, you should get a\nprototype in front of users as soon as possible.The alternative approach might be called the Hail Mary strategy.\nInstead of getting a prototype out quickly and gradually refining\nit, you try to create the complete, finished, product in one long\ntouchdown pass.  As far as I know, this is a\nrecipe for disaster.  Countless startups destroyed themselves this\nway during the Internet bubble.  I've never heard of a case\nwhere it worked.What people outside the software world may not realize is that\nWorse is Better is found throughout the arts.\nIn drawing, for example, the idea was discovered during the\nRenaissance.  Now almost every drawing teacher will tell you that\nthe right way to get an accurate drawing is not to\nwork your way slowly around the contour of an object, because errors will\naccumulate and you'll find at the end that the lines don't meet.\nInstead you should draw a few quick lines in roughly the right place,\nand then gradually refine this initial sketch.In most fields, prototypes\nhave traditionally been made out of different materials.\nTypefaces to be cut in metal were initially designed  \nwith a brush on paper.  Statues to be cast in bronze   \nwere modelled in wax.  Patterns to be embroidered on tapestries\nwere drawn on paper with ink wash.  Buildings to be\nconstructed from stone were tested on a smaller scale in wood.What made oil paint so exciting, when it\nfirst became popular in the fifteenth century, was that you\ncould actually make the finished work from the prototype.\nYou could make a preliminary drawing if you wanted to, but you\nweren't held to it; you could work out all the details, and\neven make major changes, as you finished the painting.You can do this in software too.  A prototype doesn't have to\nbe just a model; you can refine it into the finished product.\nI think you should always do this when you can.  It lets you\ntake advantage of new insights you have along the way.  But\nperhaps even more important, it's good for morale.Morale is key in design.  I'm surprised people\ndon't talk more about it.  One of my first\ndrawing teachers told me: if you're bored when you're\ndrawing something, the drawing will look boring.\nFor example, suppose you have to draw a building, and you\ndecide to draw each brick individually.  You can do this\nif you want, but if you get bored halfway through and start\nmaking the bricks mechanically instead of observing each one,   \nthe drawing will look worse than if you had merely suggested\nthe bricks.Building something by gradually refining a prototype is good\nfor morale because it keeps you engaged.  In software, my  \nrule is: always have working code.  If you're writing\nsomething that you'll be able to test in an hour, then you\nhave the prospect of an immediate reward to motivate you.\nThe same is true in the arts, and particularly in oil painting.\nMost painters start with a blurry sketch and gradually\nrefine it.\nIf you work this way, then in principle\nyou never have to end the day with something that actually\nlooks unfinished.  Indeed, there is even a saying among\npainters: \"A painting is never finished, you just stop\nworking on it.\"  This idea will be familiar to anyone who\nhas worked on software.Morale is another reason that it's hard to design something\nfor an unsophisticated user.   It's hard to stay interested in\nsomething you don't like yourself.  To make something  \ngood, you have to be thinking, \"wow, this is really great,\"\nnot \"what a piece of shit; those fools will love it.\"Design means making things for humans.  But it's not just the\nuser who's human.  The designer is human too.Notice all this time I've been talking about \"the designer.\"\nDesign usually has to be under the control of a single person to\nbe any good.   And yet it seems to be possible for several people\nto collaborate on a research project.  This seems to\nme one of the most interesting differences between research and\ndesign.There have been famous instances of collaboration in the arts,\nbut most of them seem to have been cases of molecular bonding rather\nthan nuclear fusion.  In an opera it's common for one person to\nwrite the libretto and another to write the music.   And during the Renaissance, \njourneymen from northern\nEurope were often employed to do the landscapes in the\nbackgrounds of Italian paintings.  But these aren't true collaborations.\nThey're more like examples of Robert Frost's\n\"good fences make good neighbors.\"  You can stick instances\nof good design together, but within each individual project,\none person has to be in control.I'm not saying that good design requires that one person think\nof everything.  There's nothing more valuable than the advice\nof someone whose judgement you trust.  But after the talking is\ndone, the decision about what to do has to rest with one person.Why is it that research can be done by collaborators and  \ndesign can't?  This is an interesting question.  I don't \nknow the answer.  Perhaps,\nif design and research converge, the best research is also\ngood design, and in fact can't be done by collaborators.\nA lot of the most famous scientists seem to have worked alone.\nBut I don't know enough to say whether there\nis a pattern here.  It could be simply that many famous scientists\nworked when collaboration was less common.Whatever the story is in the sciences, true collaboration\nseems to be vanishingly rare in the arts.  Design by committee is a\nsynonym for bad design.  Why is that so?  Is there some way to\nbeat this limitation?I'm inclined to think there isn't-- that good design requires\na dictator.  One reason is that good design has to   \nbe all of a piece.  Design is not just for humans, but\nfor individual humans.  If a design represents an idea that  \nfits in one person's head, then the idea will fit in the user's\nhead too.Related:April 2005\"Suits make a corporate comeback,\" says the New\nYork Times.  Why does this sound familiar?  Maybe because\nthe suit was also back in February,\n\nSeptember\n2004, June\n2004, March\n2004, September\n2003, \n\nNovember\n2002, \nApril 2002,\nand February\n2002.\n\nWhy do the media keep running stories saying suits are back?  Because\nPR firms tell \nthem to.  One of the most surprising things I discovered\nduring my brief business career was the existence of the PR industry,\nlurking like a huge, quiet submarine beneath the news.  Of the\nstories you read in traditional media that aren't about politics,\ncrimes, or disasters, more than half probably come from PR firms.I know because I spent years hunting such \"press hits.\"  Our startup spent\nits entire marketing budget on PR: at a time when we were assembling\nour own computers to save money, we were paying a PR firm $16,000\na month.  And they were worth it.  PR is the news equivalent of\nsearch engine optimization; instead of buying ads, which readers\nignore, you get yourself inserted directly into the stories.  [1]Our PR firm\nwas one of the best in the business.  In 18 months, they got press\nhits in over 60 different publications.  \nAnd we weren't the only ones they did great things for.  \nIn 1997 I got a call from another\nstartup founder considering hiring them to promote his company.  I\ntold him they were PR gods, worth every penny of their outrageous   \nfees.  But I remember thinking his company's name was odd.\nWhy call an auction site \"eBay\"?\nSymbiosisPR is not dishonest.  Not quite.  In fact, the reason the best PR\nfirms are so effective is precisely that they aren't dishonest.\nThey give reporters genuinely valuable information.  A good PR firm\nwon't bug reporters just because the client tells them to; they've\nworked hard to build their credibility with reporters, and they", "context_length": 12706, "depth_percent": 3}